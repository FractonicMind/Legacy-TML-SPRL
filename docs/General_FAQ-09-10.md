# TERNARY MORAL LOGIC (TML) FRAMEWORK - GENERAL FAQ

**Framework Originator**: Lev Goukassian (ORCID: 0009-0006-5966-1243)  
**Contact**: leogouk@gmail.com  
**Last Updated**: September 2025

---

## CRITICAL COMPLIANCE NOTICE

**BEFORE READING**: All TML implementations must comply with mandatory requirements in [MANDATORY.md](MANDATORY.md) and legal terms in [COMPLIANCE_DISCLAIMER.md](COMPLIANCE_DISCLAIMER.md). This FAQ supplements but does not replace those binding documents.

---

## From Explainable AI (XAI) to Auditable AI (AAI): The Paradigm Shift

### Why Auditable AI Replaces Explainable AI

The Ternary Moral Logic framework represents a fundamental shift from **Explainable AI (XAI)** to **Auditable AI (AAI)**. While XAI attempts real-time explanations that courts cannot use, AAI creates evidence that prosecutors can wield.

**XAI Failed Because:**
- Explanations are subjective interpretations with no legal standing
- Companies control the narrative
- Victims cannot prove harm
- No criminal accountability exists

**AAI Succeeds Through:**
- **Immutable evidence generation** that stands in court
- **Criminal penalties** for missing documentation  
- **Irrebuttable presumptions** - missing logs equal guilt
- **Victim access** to proof of harm
- **Executive imprisonment** for violations

TML operationalizes AAI through Moral Trace Logs that create prosecutable evidence. Every AI decision involving complex moral reasoning generates court-admissible documentation. **Missing logs equal automatic guilt.**

---

## I. FRAMEWORK FUNDAMENTALS

### Q1: What is the Ternary Moral Logic (TML) Framework?
TML is an enforcement framework that makes AI companies criminally liable for missing Moral Trace Logs. When AI systems make ethically complex decisions without proper documentation, executives face imprisonment and organizations face bankruptcy-level penalties. The framework transforms AI accountability from voluntary guidelines to mandatory law with teeth.

### Q2: What counts as an ethically complex decision?
Any AI decision that could harm people or violate their rights:
- Medical diagnosis affecting treatment
- Loan denials impacting families
- Job application rejections
- Content moderation silencing voices
- Autonomous vehicle navigation choices
- Insurance claim decisions
- Child safety determinations
- Elder care recommendations

If AI makes choices affecting human welfare, dignity, or rights, it requires Moral Trace Logs.

### Q3: What is the Sacred Pause?
The Sacred Pause is a mandatory checkpoint for AI - also called the **AI Heart Beat (AIHB)**. When an AI system faces an ethically complex decision, it generates a detailed Moral Trace Log recording who might be affected, what risks exist, and why it chose its action. 

Think of it like a security camera that only records when something important happens. Without the AI Heart Beat, an AI is just a silent machine. With it, every action carries proof of life.

### Q4: What are the three states of TML?
- **+1 (Proceed)**: Low-risk decision, basic record keeping
- **0 (Sacred Pause)**: Ethically complex decision, detailed Moral Trace Logs required
- **-1 (Prohibit)**: Too dangerous, AI must refuse and document why

When AI blocks an action (-1), it MUST create complete documentation explaining the prohibition. Missing prohibition logs create liability.

### Q5: Does TML affect AI performance?
**No. TML has ZERO impact on AI response time.** The AI responds immediately to users while Moral Trace Logs generate asynchronously in the background. Just as a car's black box recorder doesn't affect driving performance, TML doesn't slow AI responses.

The logs are written in parallel, in background processing, with no impact on AI performance whatsoever. Companies cannot use performance as an excuse. Missing logs create criminal liability regardless of latency concerns.

### Q6: How are logs distributed to institutions?
Sacred Pause logs are distributed to all 11 independent institutions in **real-time** as soon as each log is created. The [Hybrid Shield Model](../Hybrid-Shield.md) ensures instant synchronization across the entire consortium, providing immediate protection against erasure or tampering attempts.

---

## II. SPRL (STAKEHOLDER PROPORTIONAL RISK LEVEL) EXPLAINED

### Q7: What is SPRL (Stakeholder Proportional Risk Level)?
SPRL is the pulse of the AI Heart Beat - a risk score measuring how an AI decision might harm different people. It considers:
- Who could be affected (stakeholders)
- How severely they could be harmed (impact)
- How likely the harm is (probability)
- Whether vulnerable people are involved (children, elderly, disabled)

Think of SPRL like a weather warning system - higher numbers mean more danger, requiring more documentation.

### Q8: How do companies calculate SPRL?
```python
# Companies implement SPRL calculation
def calculate_sprl(decision, context):
    stakeholders = identify_affected_people(decision)
    risk_per_stakeholder = assess_individual_risks(stakeholders)
    vulnerability_factor = check_for_vulnerable_groups(stakeholders)
    
    # Company sets their own thresholds
    if risk_score > company_threshold:
        trigger_sacred_pause()  # Must generate logs
    
    return risk_score
```

Each company decides their thresholds, but they face full liability for getting it wrong.

### Q9: Who is responsible for SPRL calculations?
Companies bear absolute liability. TML provides the methodology - companies face consequences:
- Incorrect calculations = fraud charges
- Inappropriate thresholds = criminal negligence
- Gaming the system = executive imprisonment
- Missing logs = automatic guilt

TML creators bear zero responsibility for implementation failures.

### Q10: What if companies set SPRL thresholds to avoid logging?
Setting thresholds extremely low (like 0.1) but generating no logs proves fraud:

**Gaming Indicators:**
- Not detecting affected people (stakeholder blindness)
- Manipulating risk calculations
- Deleting generated logs
- Using fake "safe" templates
- Cosmetic compliance only

**Rule: Low thresholds create "log floods." Silence proves fraud.**

Setting thresholds extremely high (like 0.9) to avoid logging also proves fraud:

**High Threshold Gaming:**
- Only catastrophic risks generate logs
- Redefining "risk" to stay below thresholds
- Never blocking obvious dangers
- Labeling harmful actions "safe"
- No evidence when victims need it

**Rule: High thresholds create "log droughts." Too few logs proves gaming.**

Upon federal adoption, prosecutors can demand code reviews and pursue criminal charges under applicable fraud statutes.

---

## III. VICTIM RIGHTS AND SUPPORT

### Q11: What rights do AI victims have under TML?
Victims gain powerful legal weapons:
- **Right to demand Moral Trace Logs** proving what AI did
- **Automatic liability** when logs are missing
- **Free legal representation** from Memorial Fund
- **Expert witnesses** explaining the harm
- **Class action coordination** for systematic violations
- **Priority support** for vulnerable victims
- **Criminal prosecution** of responsible executives

Missing logs shift burden to defendants to prove innocence.

### Q12: How does the Lev Goukassian Memorial Fund help victims?
The Memorial Fund provides comprehensive support:
- **Emergency medical assistance** for AI-caused injuries
- **Legal teams** pursuing maximum compensation
- **Expert testimony** proving negligence
- **Investigation support** uncovering violations
- **Public advocacy** preventing future harm
- **Psychological support** for trauma victims
- **Financial assistance** during legal proceedings

All funded by penalties from violators, not taxpayers.

### Q13: How do victims seek compensation through TML?
Step-by-step path to justice:
1. **Report harm** to Memorial Fund or attorney
2. **Request Moral Trace Logs** through legal channels
3. **Missing logs = automatic liability** (company must prove innocence)
4. **Memorial Fund provides** immediate emergency support
5. **Legal team pursues** criminal and civil charges
6. **Penalties fund** victim compensation
7. **Public disclosure** prevents repeated harm

### Q14: How do penalties finance victim support?
Every penalty dollar has a purpose:

- 30% to Memorial Fund for victim support (with priority to vulnerable populations)
- 15% to whistleblowers who exposed violations
- 25% to enforcement infrastructure
- 20% to council operations
- 10% to public education about AI rights
- 0% to general government - all serves TML mission

---

## IV. LEGAL FRAMEWORK

### Q15: What criminal penalties enforce TML compliance?
Upon federal adoption, violations trigger existing criminal statutes:

**United States:**
- False attestation: 18 U.S.C. ยง 1001 (up to 5 years imprisonment)
- Log tampering: 18 U.S.C. ยง 1519 (up to 20 years imprisonment)
- Threshold gaming: Wire fraud with treble damages

**All Jurisdictions Apply:**
- Evidence tampering charges
- Fraud and negligence prosecutions
- Percentage of global revenue fines
- Executive personal imprisonment
- Corporate dissolution for repeat violations

"I didn't know" is never a defense under these established legal standards.

### Q16: Are Moral Trace Logs admissible in court?
Yes. Logs are designed as prosecutorial weapons:
- **Authentication**: Federal rules - cryptographic signatures prove authenticity
- **Self-authentication**: Certified electronic records
- **Business records**: Logs made in regular operation
- **Missing logs = guilt**: Irrebuttable presumption shifts burden
- **Criminal penalties**: Evidence tampering statutes for destroying logs

Judges and juries understand: No logs means hiding guilt.

### Q17: How is chain of custody maintained?
Chain of custody makes Moral Trace Logs legally unassailable:
- **Automatic access logging**: Every view creates cryptographic receipt
- **Transfer records**: Time-stamped signatures prove location
- **Verification events**: Integrity checks create audit trail
- **Immutable storage**: Write-once systems prevent alteration
- **Blockchain anchoring**: Periodic hash commitments

Any gap in chain weakens evidence. Complete chain makes evidence bulletproof.

---

## V. WHISTLEBLOWER PROTECTION

### Q18: How does TML protect whistleblowers?
Aggressive protection with substantial rewards:
- **Guaranteed anonymity** through secure channels
- **15% of all recovered penalties** as rewards
- **Criminal prosecution** for retaliation (adds 5-10 years to sentences)
- **Real-time reporting** to council (bypasses management)
- **Memorial Fund** provides legal protection
- **Lifetime protection** from industry blacklisting

### Q19: What prevents false whistleblower claims?
Strong safeguards against abuse:
- **Evidence required** before any rewards
- **Criminal prosecution** for false reports
- **Independent investigation** verifies claims
- **Pattern detection** identifies coordinated fraud
- **Clawback provisions** recover false rewards
- **Industry blacklist** for proven false reporters

Report real violations, get rich. File false claims, go to prison.

---

## VI. GOVERNANCE

### Q20: Who oversees TML implementations?
The 11-institution governance council with enforcement powers:

**Academic Institutions:**
- Stanford University
- Massachusetts Institute of Technology (MIT)
- Harvard University
- Oxford University
- Cambridge University

**Research Organizations:**
- Brookings Institution
- RAND Corporation
- Alan Turing Institute

**International Organizations:**
- United Nations (UN)
- World Health Organization (WHO)
- European Commission

Council uses weighted voting with rotating leadership. No single institution controls decisions. Unanimous criminal referrals trigger automatic prosecution.

### Q21: What investigation powers does the council have?
Sweeping authority for accountability:
- **Unlimited read access** to all Moral Trace Logs at any given moment
- **Subpoena power** for missing documentation
- **Criminal referral** authority to prosecutors
- **Public disclosure** rights for violations
- **Whistleblower reward** authorization (15% of penalties)
- **Emergency intervention** for imminent harm

Organizations cannot refuse or delay council access. Obstruction adds charges.

### Q22: How do institutions access logs for investigation?
Structured protocols ensure accountability:
- **Read-only viewing** with cryptographic receipts
- **Time-limited access** for specific investigations
- **Court supervision** for sensitive cases
- **Victim priority** for relevant logs
- **Public summaries** of findings

Access creates evidence trails preventing abuse.

### Q23: How are violations detected and prosecuted?
Multi-layered enforcement ensures capture:
- **Automated detection** flags missing logs
- **Statistical analysis** reveals gaming patterns
- **Whistleblower reports** trigger investigations
- **Victim complaints** demand log reviews
- **Random audits** catch hidden violations
- **Competitor reports** expose outliers

Every violation path leads to prosecution.

---

## VII. TECHNICAL IMPLEMENTATION

### Q24: How do organizations implement TML?
```python
from tml_framework import TMLEngine

# Initialize with risk thresholds
tml = TMLEngine(
    sacred_pause_threshold=0.4,  # Your liability starts here
    prohibition_threshold=0.8    # Blocking mandatory here
)

def ai_decision(query, context):
    # Calculate risk (YOU are liable for accuracy)
    sprl = tml.calculate_sprl(query, context)
    
    # Prohibition MUST block and log
    if sprl >= 0.8:
        tml.generate_prohibition_trace(query, context, sprl)  # Required
        return tml.block_action("Prohibited by TML")
    
    # AI responds immediately - NO LATENCY IMPACT
    response = ai_system.process(query)
    
    # Sacred Pause logs generate in background
    if sprl >= 0.4:
        tml.generate_moral_trace_async(query, context, sprl)
    
    return response
```

Failure to implement correctly creates criminal liability.

### Q25: Are Moral Trace Logs truly immutable?
Absolutely tamper-proof with criminal consequences:
- **Hardware security modules** create signatures
- **Blockchain anchoring** ensures permanence
- **Write-once storage** prevents changes
- **Any tampering** triggers alerts and prosecution
- **18 U.S.C. ยง 1519 charges** for any modifications

Attempting to alter logs guarantees prosecution under existing federal law.

### Q26: How do logs handle storage efficiently?
Smart compression without losing evidence:
- **Template patterns** for common scenarios
- **Full details** for novel situations
- **Reference linking** reduces redundancy
- **Complete audit trails** always maintained

Storage costs never excuse missing logs.

### Q27: What about vulnerable populations?
Enhanced protection with severe penalties:
- **Lower thresholds** mandatory for vulnerable groups
- **Maximum documentation** required
- **Expedited investigation** for violations
- **Priority victim support** (40% of penalties)
- **Aggravated charges** for executives
- **Mandatory reporting** to protective agencies

Harming vulnerable populations triggers maximum penalties.

### Q28: Can TML scale to billions of interactions?
Scale provides no excuse:
- **Distributed processing** handles volume
- **Pattern recognition** optimizes storage
- **Background logging** maintains speed
- **Regional coordination** enables investigation

"Too big to log" means too dangerous to operate.

### Q29: What about edge devices and IoT?
Resource constraints provide no exemption:
- **Lightweight implementations** required
- **Local logging** mandatory
- **Periodic synchronization** for investigation
- **Central liability** for edge failures

Every smart device must maintain accountability.

---

## VIII. INTEGRATION AND MIGRATION

### Q30: How does TML integrate with existing regulations?
TML becomes the evidence layer for all AI laws:

**EU AI Act**: Logs prove risk assessment and transparency  
**GDPR Article 22**: Traces provide automated decision explanations  
**HIPAA**: Documentation shows patient safety considerations  
**NIST Standards**: Records verify bias mitigation actually occurred  
**International Law**: Cryptographic signatures recognized globally

One framework satisfies all regulatory requirements.

### Q31: How do organizations migrate to TML?
Systematic deployment with no excuses:
1. **Install TML** alongside existing systems
2. **Set thresholds** (gaming them = fraud)
3. **Validate coverage** (gaps = liability)
4. **Test protocols** (failures = negligence)
5. **Go live** with full accountability

"Still migrating" provides no legal defense.

### Q32: Can TML work with any AI system?
Universal compatibility, no technical excuses:
- **All frameworks** must integrate
- **Cloud providers** share liability
- **Language models** require traces
- **Legacy systems** need retrofitting
- **Custom AI** follows same rules

"Incompatible with our system" admits guilt.

### Q33: Why not rely on company safeguards?
Company safeguards are theater. TML creates evidence:
- **Safeguards** are private and unverifiable
- **TML logs** are immutable and court-admissible
- **Safeguards** protect companies from liability
- **TML** protects society with prosecution
- **Safeguards** fail silently
- **TML failures** trigger prosecutions

"We have safeguards" without TML logs equals admission of negligence.

### Q34: How does TML coordinate across jurisdictions?
Universal evidence with local enforcement:
- **Moral Trace Logs** admissible globally under international evidence standards
- **Each country** applies its own criminal penalties
- **International council** coordinates investigations
- **No safe harbors** for executives who flee
- **Extradition** for serious violations
- **Asset freezing** across borders

Companies cannot hide in friendly jurisdictions.

---

## IX. ADVANCED TOPICS

### Q35: How does TML handle multi-agent AI systems?
Every agent bears responsibility:
- **Individual logs** per agent required
- **Coordination traces** document interactions
- **Missing logs** from any agent = total liability
- **Emergent behavior** must be logged
- **Distributed accountability** with central responsibility

Complex systems require complete documentation.

### Q36: What about future AGI systems?
AGI makes TML more critical, not optional:
- **Value learning** requires complete documentation
- **Safety analysis** depends on Moral Trace Logs
- **Democratic oversight** becomes existential
- **Missing AGI logs** trigger emergency shutdown
- **Unlogged AGI** equals criminal negligence

Advanced AI demands advanced accountability.

### Q37: If AGI is so powerful, why wouldn't it just hide or fake the logs?  
Because logging runs outside the AGI. Every decision call is wrapped: the AGI executes immediately, while a background task records the log in parallel. Logs are sealed in tamper-proof external storage (universities, NGOs, blockchain anchors). The AGI never controls or even sees this process.

### Q38: Could organizations misuse the Sacred Pause to shift liability onto humans?
No. Every Sacred Pause generates a Moral Trace Log that records why the pause was triggered and what options were presented. If a system is designed to offload responsibility in bad faith, the logs expose that pattern. Liability attaches to the organization that built or deployed the system, not to the human forced into last-second decisions.

### Q39: Could an AI abuse the Sacred Pause to avoid hard questions?
Attempts at "malicious compliance" are visible in the logs. If an AI pauses abnormally often in safe or routine cases, that behavior itself is recorded and auditable. Overuse of the pause becomes evidence of system failure or manipulation, not a shield against accountability.

### Q40: How will TML adapt to new technologies?
Evolution maintains enforcement:
- **Automatic coverage** of new capabilities
- **Improved detection** algorithms
- **Increased penalties** for powerful AI
- **Retroactive prosecution** for discovered violations
- **No grandfather clauses** for old systems

Technology advances, accountability remains.

### Q41: What makes TML different from other AI safety approaches?
TML has teeth. Others have suggestions:
- **Real prison sentences** not ethics boards
- **Missing logs = guilt** not "areas for improvement"
- **Victim compensation** not corporate apologies
- **Whistleblower millions** not anonymous hotlines
- **Criminal prosecution** not self-regulation

TML transforms AI safety from corporate PR to criminal law.

### Q42: How is TML compliance verified?
An automated validator checks every TML implementation for:
- **Creator attribution** - Must credit Lev Goukassian (ORCID: 0009-0006-5966-1243)
- **Core concepts** - Must implement Ternary Moral Logic, Sacred Pause, Moral Trace Logs
- **Required documentation** - Must include implementation guides and FAQs
- **SPRL calculations** - Must show actual risk assessment code

**Validation failures create liability:**
- Using TML without attribution = intellectual property theft
- Missing core concepts = fraudulent TML claim
- Incomplete implementation = negligent deployment
- Failed validation = evidence of bad faith

Organizations cannot claim "TML compliance" without passing validation. False claims trigger additional fraud charges.

The validator is public. Anyone can verify if a company legitimately implements TML or is lying about compliance.

---

## SUPPORT

**Implementation Guide**: https://github.com/fractonicmind/TernaryMoralLogic/blob/main/docs/IMPLEMENTATION_GUIDE.md  
**Legal Framework**: https://github.com/fractonicmind/TernaryMoralLogic/blob/main/docs/MANDATORY.md  
**Council Governance**: https://github.com/fractonicmind/TernaryMoralLogic/blob/main/governance/council_charter.md  
**Whistleblower Protection**: https://github.com/fractonicmind/TernaryMoralLogic/blob/main/governance/whistleblower_protection.md  
**Whistleblower Portal**: https://github.com/fractonicmind/TernaryMoralLogic/blob/main/governance/whistleblower_reporting.md  
**Victim Protection**: https://github.com/fractonicmind/TernaryMoralLogic/blob/main/governance/victim_protection.md  
**Victim Portal**: https://github.com/fractonicmind/TernaryMoralLogic/blob/main/governance/victim_reporting.md  
**Memorial Fund**: https://github.com/fractonicmind/TernaryMoralLogic/blob/main/memorial/MEMORIAL_FUND.md

**Creator Contact**: leogouk@gmail.com  
**Repository**: https://github.com/fractonicmind/TernaryMoralLogic

---

## CLOSING STATEMENT

TML transforms AI accountability from voluntary guidelines to mandatory criminal law. Missing logs equal guilt. Gaming equals fraud. Violations equal imprisonment.

**The age of unaccountable AI ends when TML becomes law.**
